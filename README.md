# Introduction

The following outlines the project details for the first project submission, Navigation for the Udacity Ud893 Deep Reinforcement Learning Nanodegree (DRLND).

# Getting Started

## The Environment

The goal of the project is to develop and train an agent to navigate in a large, square world (environment) and collect items - specifically, to collect yellow bananas, while avoiding blue bananas. This environment is similar to the Banana Collector environment on the [Unity ML-Agents GitHub page](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Learning-Environment-Examples.md#banana-collector).

## Install and Dependencies

The following instructions will help you set up the environment on your machine.

### Step 1 - Clone the Repository

All files required for running the project are in the main project directory. Note that a copy of the `python/` directory from the [DRLND](https://github.com/udacity/deep-reinforcement-learning#dependencies) which contains additional dependencies has also been included in the main project directory.

### Step 2 - Download the Unity Environment

Note that if your operating system is Windows (64-bit), the Unity environment is included for that OS in the main project directory and you can skip this section. If you're using a different operating system, download the file you require from one of the following links:

- Linux: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P1/Banana/Banana_Linux.zip)
- Mac OSX: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P1/Banana/Banana.app.zip)
- Windows (32-bit): [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P1/Banana/Banana_Windows_x86.zip)

Then, place the file in the main project directory folder and unzip (or decompress) the file.

## Instructions

The [Report.md](Report.md) file (also available in notebook format `Report.ipynb`) is a project summary report which includes a decription of the implementation, learning algorithm(s), hyperparameters, neural net model architectures, reward/episode plots and ideas for future work. The summary report should be read first as it explains the order in which to run the project notebook. The `Project 1.ipynb` jupyter notebook provides the code for running and training the actual agent(s).
